# battle: https://github.com/wsjeon/maddpg-rllib
group: "Gym"
name: "share/dqn_cartpole"

training:
  interface:
    type: "independent"
    population_size: -1
  config:
    # control the frequency of remote parameter update
    update_interval: 1
    saving_interval: 10
    batch_size: 64
    optimizer: "Adam"
    lr: 0.01
    tau: 0.01  # soft update

rollout:
  type: "async"
  stopper: "simple_rollout"
  stopper_config:
    max_step: 1000
  metric_type: "simple"
  fragment_length: 200
  num_episodes: 1
  num_env_per_worker: 1
  terminate: "any"
  callback: "simultaneous"

env_description:
  creator: "Gym"
  config:
    env_id: "CartPole-v1"

algorithms:
  DQN:
    name: "DQN"
    model_cofig:
      critic:
        network: mlp
        layers:
          - units: 64
            activation: ReLU
          - units: 64
            activation: ReLU
        output:
          activation: False
    custom_config:
      gamma: 0.98
      eps_max: 1.0
      eps_min: 0.1
      eps_anneal_time: 10000

global_evaluator:
  name: "generic"

dataset_config:
  episode_capacity: 100000
  learning_start: 500
